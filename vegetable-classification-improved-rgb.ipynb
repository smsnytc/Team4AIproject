{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D\nfrom keras.optimizers import Adam\nfrom keras.layers import MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reduce the size of the images to reduce the model size. 128x128 = 812MB\n#Rescale the image sizes to between 0 and 1\ntrain_img_datagen = ImageDataGenerator(rescale=1./255)\nval_img_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_set = train_img_datagen.flow_from_directory(\n    '../input/vegtrainset',\n    target_size=(64,64),\n    batch_size=32,\n    color_mode='rgb',\n    class_mode='categorical')\n\nval_set = val_img_datagen.flow_from_directory(\n    '../input/vegtestset',\n    target_size=(64,64),\n    batch_size=32,\n    color_mode='rgb',\n    class_mode='categorical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_dict = {'flower': 0,'fruit': 1,'root': 2,'seed': 3}\n\nclass_names = list(class_dict.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(filters=32, kernel_size=1, input_shape=(64,64,3)),\n    Flatten(input_shape=(64, 64)), #flatten --> 3D to 2D\n    Dense(16, activation='relu'),\n    #Dense(2, activation='softmax')\n    Dense(4,activation='softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use BinaryCrossentropy for classification of 0 and 1\n#https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_info = model.fit(train_set,batch_size=32, validation_data= val_set, epochs=5, shuffle=True)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# list all data in history\nprint(model_info.history.keys())\n\n# summarize history for accuracy\nplt.plot(model_info.history['accuracy'])\nplt.plot(model_info.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(model_info.history['loss'])\nplt.plot(model_info.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('VegRGBWorking.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('VegRGBWorking.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# dimensions of our images\nimg_width, img_height = 64, 64\nimages_dir = \"../input/vegtestset\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting single image\nimage_path = \"../input/validatedataset/Tomato2.jpg\"\nnew_img = image.load_img(image_path, target_size=(img_width, img_height))\nimg = image.img_to_array(new_img)\nimg = np.expand_dims(img, axis=0)\nimg = img/255\n\n#img_class = model.predict_classes(img) #returns ndim np_array\nimg_class = np.argmax(model.predict(img), axis=-1)\nimg_class_index = img_class.item() #extracting value(s)\nclassname = class_names[img_class_index]\n\n#img_prob = model.predict_proba(img) #returns numpy array of class probabilities\nimg_prob = model.predict(img)\nprediction_prob = img_prob.max()\n\npred_dict = {\"Class\":classname, \"Probability\":prediction_prob}\nprint(pred_dict)\n\n#ploting image with predicted class name        \nplt.figure(figsize = (4,4))\nplt.imshow(new_img)\nplt.axis('off')\nplt.title(classname)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}